{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bf62f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3%"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/tanglongbin/NLP/nlp/part-2/try_part2_2_NLKT.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 81>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/tanglongbin/NLP/nlp/part-2/try_part2_2_NLKT.ipynb#ch0000000vscode-remote?line=77'>78</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/tanglongbin/NLP/nlp/part-2/try_part2_2_NLKT.ipynb#ch0000000vscode-remote?line=80'>81</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/tanglongbin/NLP/nlp/part-2/try_part2_2_NLKT.ipynb#ch0000000vscode-remote?line=81'>82</a>\u001b[0m     main()\n",
      "\u001b[1;32m/home/tanglongbin/NLP/nlp/part-2/try_part2_2_NLKT.ipynb Cell 1\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/tanglongbin/NLP/nlp/part-2/try_part2_2_NLKT.ipynb#ch0000000vscode-remote?line=66'>67</a>\u001b[0m OutPutPath_nltk \u001b[39m=\u001b[39m OutTemplateFile_nltk \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(cnt) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.txt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/tanglongbin/NLP/nlp/part-2/try_part2_2_NLKT.ipynb#ch0000000vscode-remote?line=67'>68</a>\u001b[0m OutPutFile_nltk \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(OutPutPath_nltk, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m,encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/tanglongbin/NLP/nlp/part-2/try_part2_2_NLKT.ipynb#ch0000000vscode-remote?line=68'>69</a>\u001b[0m Get_word_nltk(FilePath, OutPutFile_nltk)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/tanglongbin/NLP/nlp/part-2/try_part2_2_NLKT.ipynb#ch0000000vscode-remote?line=69'>70</a>\u001b[0m \u001b[39m# 输出程序完成百分比\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/tanglongbin/NLP/nlp/part-2/try_part2_2_NLKT.ipynb#ch0000000vscode-remote?line=70'>71</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m\"\u001b[39m,end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/home/tanglongbin/NLP/nlp/part-2/try_part2_2_NLKT.ipynb Cell 1\u001b[0m in \u001b[0;36mGet_word_nltk\u001b[0;34m(FilePath, OutPutFile)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/tanglongbin/NLP/nlp/part-2/try_part2_2_NLKT.ipynb#ch0000000vscode-remote?line=53'>54</a>\u001b[0m txt_data \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mreadlines()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/tanglongbin/NLP/nlp/part-2/try_part2_2_NLKT.ipynb#ch0000000vscode-remote?line=54'>55</a>\u001b[0m txt_data\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m(txt_data) \n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/tanglongbin/NLP/nlp/part-2/try_part2_2_NLKT.ipynb#ch0000000vscode-remote?line=55'>56</a>\u001b[0m cutwords \u001b[39m=\u001b[39m word_tokenize(txt_data) \u001b[39m#分词\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/tanglongbin/NLP/nlp/part-2/try_part2_2_NLKT.ipynb#ch0000000vscode-remote?line=56'>57</a>\u001b[0m cutwords \u001b[39m=\u001b[39m delete_characters(cutwords)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/tanglongbin/NLP/nlp/part-2/try_part2_2_NLKT.ipynb#ch0000000vscode-remote?line=57'>58</a>\u001b[0m OutPutFile\u001b[39m.\u001b[39mwrite(\u001b[39mstr\u001b[39m(cutwords))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/tokenize/__init__.py:130\u001b[0m, in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39mReturn a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39musing NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m:type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m sentences \u001b[39m=\u001b[39m [text] \u001b[39mif\u001b[39;00m preserve_line \u001b[39melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[0;32m--> 130\u001b[0m \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m    131\u001b[0m     token \u001b[39mfor\u001b[39;00m sent \u001b[39min\u001b[39;00m sentences \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m _treebank_word_tokenizer\u001b[39m.\u001b[39mtokenize(sent)\n\u001b[1;32m    132\u001b[0m ]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/tokenize/__init__.py:131\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39mReturn a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39musing NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m:type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m sentences \u001b[39m=\u001b[39m [text] \u001b[39mif\u001b[39;00m preserve_line \u001b[39melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[1;32m    130\u001b[0m \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m--> 131\u001b[0m     token \u001b[39mfor\u001b[39;00m sent \u001b[39min\u001b[39;00m sentences \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m _treebank_word_tokenizer\u001b[39m.\u001b[39;49mtokenize(sent)\n\u001b[1;32m    132\u001b[0m ]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/tokenize/destructive.py:182\u001b[0m, in \u001b[0;36mNLTKWordTokenizer.tokenize\u001b[0;34m(self, text, convert_parentheses, return_str)\u001b[0m\n\u001b[1;32m    179\u001b[0m     text \u001b[39m=\u001b[39m regexp\u001b[39m.\u001b[39msub(substitution, text)\n\u001b[1;32m    181\u001b[0m \u001b[39mfor\u001b[39;00m regexp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mCONTRACTIONS2:\n\u001b[0;32m--> 182\u001b[0m     text \u001b[39m=\u001b[39m regexp\u001b[39m.\u001b[39;49msub(\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39m1 \u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39m2 \u001b[39;49m\u001b[39m\"\u001b[39;49m, text)\n\u001b[1;32m    183\u001b[0m \u001b[39mfor\u001b[39;00m regexp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mCONTRACTIONS3:\n\u001b[1;32m    184\u001b[0m     text \u001b[39m=\u001b[39m regexp\u001b[39m.\u001b[39msub(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\\\u001b[39m\u001b[39m1 \u001b[39m\u001b[39m\\\u001b[39m\u001b[39m2 \u001b[39m\u001b[39m\"\u001b[39m, text)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "import os\n",
    "\n",
    "# 数据读写文件路径\n",
    "TextPath = \"/home/tanglongbin/NLP/parsed_data\" \n",
    "OutTemplateFile_nltk = \"/home/tanglongbin/NLP/nltk_text/nltk\"\n",
    "\n",
    "# 最后修改时间：2022/8/5 9：00\n",
    "# 最后修改者：熊翔翔\n",
    "#此程序仍存在问题 一些字符例如：\\\\n，5-23等没有被清理\n",
    "\n",
    "# 获取指定文件夹内的所有文件的绝对路径\n",
    "# return type: List\n",
    "def GetFilePath(DirPath):\n",
    "    \n",
    "    Res = []\n",
    "    for FilePath, DirNames, FileNames in os.walk(DirPath):\n",
    "        for FileName in FileNames:\n",
    "            str_tmp = os.path.join(FilePath, FileName)\n",
    "            Res.append(str_tmp)\n",
    "            \n",
    "    return Res\n",
    "\n",
    "def is_number(s):\n",
    "    '''\n",
    "        判断字符串是否为数字\n",
    "    '''\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        pass\n",
    " \n",
    "    try:\n",
    "        import unicodedata\n",
    "        unicodedata.numeric(s)\n",
    "        return True\n",
    "    except (TypeError, ValueError):\n",
    "        pass\n",
    " \n",
    "    return False\n",
    "\n",
    "\n",
    "def delete_characters(token_words):\n",
    "    characters = [' ',',', '.','DBSCAN', ':', ';', '?', '(', ')', '[', ']', '&', '!', '*', '@', '#', '$', '%','-','...','^','{','}','/','=','>','<','+']\n",
    "    words_list = [word for word in token_words if word not in characters and not is_number(word)]\n",
    "    return words_list\n",
    "    \n",
    "    \n",
    "    \n",
    "#分词\n",
    "def Get_word_nltk(FilePath, OutPutFile):\n",
    "    with open(FilePath,'r',encoding='utf-8') as f:\n",
    "        txt_data = f.readlines()\n",
    "        txt_data=str(txt_data)\n",
    "        cutwords = word_tokenize(txt_data) #分词\n",
    "        cutwords = delete_characters(cutwords)\n",
    "        OutPutFile.write(str(cutwords))\n",
    "    return\n",
    "\n",
    "def main():\n",
    "    # 获取所有文件路径并依次遍历\n",
    "    FilePaths = GetFilePath(TextPath)\n",
    "    cnt = 0\n",
    "    total = len(FilePaths)\n",
    "    for FilePath in FilePaths:\n",
    "        OutPutPath_nltk = OutTemplateFile_nltk + \"_\" + str(cnt) + \".txt\"\n",
    "        OutPutFile_nltk = open(OutPutPath_nltk, \"w\",encoding=\"utf-8\")\n",
    "        Get_word_nltk(FilePath, OutPutFile_nltk)\n",
    "        # 输出程序完成百分比\n",
    "        print(\"\\r\",end=\"\")\n",
    "        print(100* cnt//total, end=\"%\")\n",
    "        cnt += 1\n",
    "        OutPutFile_nltk.close()\n",
    "        \n",
    "    print(\"done\")\n",
    "\n",
    "    return\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82691c00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

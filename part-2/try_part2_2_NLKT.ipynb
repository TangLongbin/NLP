{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bf62f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90%done\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "import os\n",
    "\n",
    "# 数据读写文件路径\n",
    "TextPath = \"D:/try/parsed_text\" \n",
    "OutTemplateFile_nltk = \"D:/try/nltk_text/nltk\"\n",
    "\n",
    "# 最后修改时间：2022/8/5、9：00\n",
    "# 最后修改者：熊翔翔\n",
    "#此程序仍存在问题 一些字符例如：\\\\n，5-23等没有被清理\n",
    "\n",
    "# 获取指定文件夹内的所有文件的绝对路径\n",
    "# return type: List\n",
    "def GetFilePath(DirPath):\n",
    "    \n",
    "    Res = []\n",
    "    for FilePath, DirNames, FileNames in os.walk(DirPath):\n",
    "        for FileName in FileNames:\n",
    "            str_tmp = os.path.join(FilePath, FileName)\n",
    "            Res.append(str_tmp)\n",
    "            \n",
    "    return Res\n",
    "\n",
    "def is_number(s):\n",
    "    '''\n",
    "        判断字符串是否为数字\n",
    "    '''\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        pass\n",
    " \n",
    "    try:\n",
    "        import unicodedata\n",
    "        unicodedata.numeric(s)\n",
    "        return True\n",
    "    except (TypeError, ValueError):\n",
    "        pass\n",
    " \n",
    "    return False\n",
    "\n",
    "\n",
    "def delete_characters(token_words):\n",
    "    characters = [' ',',', '.','DBSCAN', ':', ';', '?', '(', ')', '[', ']', '&', '!', '*', '@', '#', '$', '%','-','...','^','{','}','/','=','>','<','+']\n",
    "    words_list = [word for word in token_words if word not in characters and not is_number(word)]\n",
    "    return words_list\n",
    "    \n",
    "    \n",
    "    \n",
    "#分词\n",
    "def Get_word_nltk(FilePath, OutPutFile):\n",
    "    with open(FilePath,'r', encoding='gb18030', errors='ignore') as f:\n",
    "        txt_data = f.readlines()\n",
    "        txt_data=str(txt_data) \n",
    "        cutwords = word_tokenize(txt_data) #分词\n",
    "        cutwords = delete_characters(cutwords)\n",
    "        OutPutFile.write(str(cutwords))\n",
    "    return\n",
    "\n",
    "def main():\n",
    "    # 获取所有文件路径并依次遍历\n",
    "    FilePaths = GetFilePath(TextPath)\n",
    "    cnt = 0\n",
    "    total = len(FilePaths)\n",
    "    for FilePath in FilePaths:\n",
    "        OutPutPath_nltk = OutTemplateFile_nltk + \"_\" + str(cnt) + \".txt\"\n",
    "        OutPutFile_nltk = open(OutPutPath_nltk, \"w\",encoding=\"utf-8\")\n",
    "        Get_word_nltk(FilePath, OutPutFile_nltk)\n",
    "        # 输出程序完成百分比\n",
    "        print(\"\\r\",end=\"\")\n",
    "        print(100* cnt//total, end=\"%\")\n",
    "        cnt += 1\n",
    "        OutPutFile_nltk.close()\n",
    "        \n",
    "    print(\"done\")\n",
    "\n",
    "    return\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82691c00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch0]",
   "language": "python",
   "name": "conda-env-pytorch0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35165d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90%done\n"
     ]
    }
   ],
   "source": [
    "#part2.3_BPE\n",
    "import os\n",
    "#install Huggingface's transformers\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.decoders import ByteLevel as ByteLevelDecoder\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.normalizers import Lowercase, NFKC, Sequence\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "\n",
    "# 数据读写文件路径\n",
    "TextPath = \"D:/try/parsed_text\" \n",
    "OutTemplateFile_bpe = \"D:/try/BPE_text\"\n",
    "#输出文件路径\n",
    "OutOutFile_Path=os.path.abspath(OutTemplateFile_bpe)\n",
    "\n",
    "# 该程序会在同一个文件夹中产生vocab.json和merge.txt两个文件\n",
    "# 最后修改时间：2022/8/6/16：57\n",
    "# 最后修改者：熊翔翔\n",
    "\n",
    "# 获取指定文件夹内的所有文件的绝对路径\n",
    "# return type: List\n",
    "def GetFilePath(DirPath):\n",
    "    \n",
    "    Res = []\n",
    "    for FilePath, DirNames, FileNames in os.walk(DirPath):\n",
    "        for FileName in FileNames:\n",
    "            str_tmp = os.path.join(FilePath, FileName)\n",
    "            Res.append(str_tmp)\n",
    "            \n",
    "    return Res\n",
    "\n",
    "#BPE\n",
    "def BPEtoken(InputFile,OutputFile):\n",
    "    # 实例化BPE tokenizer\n",
    "    tokenizer = Tokenizer(BPE())\n",
    "    # 规范化操作包括 lower-casing 和 unicode-normalization\n",
    "    tokenizer.normalizer = Sequence([NFKC(),Lowercase()])\n",
    "    # pre-tokenizer 以空白作为词语边界\n",
    "    tokenizer.pre_tokenizer = Whitespace()\n",
    "    # plug a decoder so we can recover from a tokenized input to the original one\n",
    "    tokenizer.decoder = ByteLevelDecoder()\n",
    "    \n",
    "    # 实例化tokenizer训练实例\n",
    "    trainer = BpeTrainer(vocab_size=50000, show_progress=True)\n",
    "    tokenizer.train(trainer=trainer, files=[InputFile])\n",
    "    tokenizer.model.save(OutputFile)\n",
    "    return\n",
    "\n",
    "def main():\n",
    "    \n",
    "    # 获取所有文件路径并依次遍历\n",
    "    FilePaths = GetFilePath(TextPath)\n",
    "    cnt = 0\n",
    "    total = len(FilePaths)\n",
    "    for FilePath in FilePaths:\n",
    "        #新建一个文件夹存储vocab.json和merge.txt\n",
    "        BPEfile_name=\"bpe_{}\".format(cnt)\n",
    "        OutOutFile_name=OutOutFile_Path+\"\\\\\"+BPEfile_name\n",
    "        os.makedirs(OutOutFile_name) \n",
    "        #BPE\n",
    "        BPEtoken(FilePath, OutOutFile_name)\n",
    "        # 输出程序完成百分比\n",
    "        print(\"\\r\",end=\"\")\n",
    "        print(100* cnt//total, end=\"%\")\n",
    "        cnt += 1\n",
    "    print(\"done\")\n",
    "    return\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93848bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch0]",
   "language": "python",
   "name": "conda-env-pytorch0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

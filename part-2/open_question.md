# What are the pros and cons of the above tokenizers?(standard split(), NLTK, Byte-Pair Encoding)

---

## split
- **优点**
  - split()分词的方法是通过指定分隔符对字符串进行切片分割
  - 它的算法非常简单
  - 容易实施且不需要语料库和规则库
  - 分词速度也比较快

- **缺点**
  - 它的分词原理非常简单，没有办法将一些特殊的单词以及中间有分隔符的词区分出来，例如it's会被分割成it 和s ，C++会被分割为C，网址或者邮件地址等也会被分割成一些没有意义的字符串
  - 而且这种方法也不能适用于像汉语，日语这种词与词之间不存在分隔符的语言
  - 这种分词策略的问题是会产生一个巨大的词表，它会将文本中所有出现过的独立片段都作为不同的 token。而实际上，词表中有很多词是相关的，例如 “dog” 和 “dogs”、“run” 和 “running”，但是由于它们会被切分为不同的编号，因此模型无法了解到它们之间的关联性
  - 这种算法也不能进行其它拓展，例如去除停用词，词干提取等

---

## NLTK：
- **优点**
  - NLTK自带语料库，词性分类库等，有很多功能，例如词性分类，词干提取（Stemming），词形归一（Lemmatization）等
  - 并且支持中文分词
  - Supports the largest number of languages compared to other libraries

- **缺点**
  - 分词速度较慢
  - 不能处理一些特殊词汇
  - 不能理解词与词之间的相关性

---

## BPE：
- **优点**
  - BPE采用按子词切分的策略，这使得只用一个较小的词表，就可以很好地覆盖绝大部分的文本
  - 尤其是对于黏着语言（例如英语），可以通过串联多个子词构成几乎任意长度的复杂长词

- **缺点**
  - BPE算法复杂度高
  - 耗时更长
  - 产生的文件更大

---

>最后修改时间08/06/17:04  
>修改者：熊翔翔  
>可以自行补充 暂时只能想到这么多
